<!DOCTYPE html><html lang="zh-cn"><head><meta charset="utf-8"><title>Data-Mining-2018-Final-exam | NABIJAN's BLOG</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="Nabijan"><meta name="designer" content="minfive"><meta name="keywords" content="null"><meta name="description" content="日常学习与兴趣交流的个人博客"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="http://yoursite.com/2018/09/15/Data-Mining-2018-Final-exam/index.html"><link rel="icon" type="image/png" href="undefined" sizes="32x32"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="NABIJAN"><link rel="stylesheet" href="/scss/views/page/post.css"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(http://oo12ugek5.bkt.clouddn.com/blog/images/loader.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="NABIJAN" alt="NABIJAN"><img src="undefined" alt="NABIJAN"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li><li class="nav__item"><a href="/" alt="menu.search" title="menu.search">menu.search</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="/img/kaggle.jpeg" alt="Data-Mining-2018-Final-exam"></div><header class="post__info"><h1 class="post__title">Data-Mining-2018-Final-exam</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://nabijan.github.io/">Nabijan</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2018-09-15</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/Data-mining/">Data-Mining</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><p>#kaggle比赛<br><strong><a href="https://www.kaggle.com/c/datamining2018-final-exam" target="_blank" rel="noopener">比赛题目</a></strong>（要求及其数据都在上面）</p><p>##1. 分类算法介绍与分析—lightGBM<br>LightGBM采用Histogram算法，其思想是将连续的浮点特征离散成k个离散值，并构造宽度为k的Histogram。然后遍历训练数据，统计每个离散值在直方图中的累计统计量。在进行特征选择时，只需要根据直方图的离散值，遍历寻找最优的分割点。<br>LightGBM 是一个梯度 boosting 框架，使用基于学习算法的决策树。它可以说是分布式的，高效的，有以下优势：</p><ul><li>更快的训练效率</li><li>低内存使用</li><li>更高的准确率</li><li>支持并行化学习</li><li>可处理大规模数据</li></ul><p>lightGBM主要有以下特点：</p><ul><li>基于Histogram的决策树算法</li><li>带深度限制的Leaf-wise的叶子生长策略</li><li>直方图做差加速</li><li>直接支持类别特征(Categorical Feature)</li><li>Cache命中率优化</li><li>基于直方图的稀疏特征优化</li><li>多线程优化</li></ul><p>在 histogram 算法之上， LightGBM 进行进一步的优化。首先它抛弃了大多数 GBDT 工具使用的按层生长(level-wise) 的决策树生长策略，而使用了带有深度限制的按叶子生长 (leaf-wise) 算法。 level-wise 过一次数据可以同时分裂同一层的叶子，容易进行多线程优化，不容易过拟合。但实际上level-wise是一种低效的算法，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销。因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。leaf-wise则是一种更为高效的策略，每次从当前所有叶子中，找到分裂增益最大(一般也是数据量最大)的一个叶子，然后分裂，如此循环。因此同 level-wise 相比，在分裂次数相同的情况下，leaf-wise 可以降低更多的误差，得到更好的精度。leaf-wise 的缺点是可能会长出比较深的决策树，产生过拟合。因此 LightGBM 在leaf-wise 之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。<br>另一个比较巧妙的优化是 histogram 做差加速。一个容易观察到的现象：一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到。通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的 k 个桶。利用这个方法，LightGBM 可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。<br>参考文献：<a href="http://lightgbm.apachecn.org/cn/latest/Features.html" target="_blank" rel="noopener">http://lightgbm.apachecn.org/cn/latest/Features.html</a></p><p>##实验结果分析<br>在这次试验中，因为我的电脑的内存不够，直接训练的话，进程会会被杀死。而且老师提供根据类型分的样本，所以我想到了一个方法。<br><strong>方法：每个类别(class)单独训练，预测测试样本属于该类别的概率，并保存。这样最后就得到每个样本属于每个类别的概率，因此最后看每个样本属于哪个类别的概率最大，就视为该样本属于该类别。</strong><br><strong>具体步骤：先读取train_data_split的train_feat_class_000.mat，并且让其标签为1。然后从其他的类别(class)中随机取出2个，并且让其标签为0。再用新的数据去训练，然后读取test_data_raw.mat预测测试样本属于class_000的概率(lightGBM的predict返回输入样本的预测类别的概率)。然后保存下来。对每个train_feat_class_n.mat(每个类别样本)进行以上的操作就可以得到，每个样本属于每个类别的概率，最后看每个样本属于哪个类别的概率最大，就视为该样本属于该类别。</strong><br><strong><em>通过以上的方法得到正确率为18.2%</em></strong><br><strong>改进：</strong>因为有些类别的样本只有50个左右，这样的话正样本50多，负样本600左右了，结果不太好，所以我根据每个类别的样本数的大小来决定负样本的数量。<br><strong>改进后的代码：python</strong><br>这是预测每个样本属于每个类别的概率<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test = h5py.File(<span class="string">'../data/test_data_raw.mat'</span>)</span><br><span class="line">test = np.transpose(test[<span class="string">'test_feat'</span>])</span><br><span class="line">dtest = lgb.Dataset(test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> xrange(<span class="number">0</span>,<span class="number">397</span>):</span><br><span class="line">	n = <span class="string">"%03d"</span> % x</span><br><span class="line">	path1 = <span class="string">'../train_data_split/train_feat_class_'</span> + n + <span class="string">'.mat'</span></span><br><span class="line">	data1 = sio.loadmat(path1)</span><br><span class="line">	data1 = data1[<span class="string">'train_feat_c'</span>]</span><br><span class="line">	[r,c] = data1.shape</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> r &lt; <span class="number">200</span> :</span><br><span class="line">		newdata = np.zeros((<span class="number">396</span> + r,<span class="number">6813</span>))</span><br><span class="line">		lgb_params =  &#123;</span><br><span class="line">			<span class="string">'boosting_type'</span>: <span class="string">'gbdt'</span>,</span><br><span class="line">    		<span class="string">'objective'</span>: <span class="string">'binary'</span>,</span><br><span class="line">    		<span class="string">'min_data_in_leaf'</span>: <span class="number">12</span>,</span><br><span class="line">    		<span class="string">'num_leaves'</span>: <span class="number">8</span>,</span><br><span class="line">    		<span class="string">'learning_rate'</span>: <span class="number">0.07</span>,</span><br><span class="line">    		<span class="string">'verbosity'</span>:<span class="number">1</span>,</span><br><span class="line">		&#125;</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		newdata = np.zeros((<span class="number">396</span>*<span class="number">2</span> + r,<span class="number">6813</span>))</span><br><span class="line">		lgb_params =  &#123;</span><br><span class="line">			<span class="string">'boosting_type'</span>: <span class="string">'gbdt'</span>,</span><br><span class="line">    		<span class="string">'objective'</span>: <span class="string">'binary'</span>,</span><br><span class="line">    		<span class="string">'min_data_in_leaf'</span>: <span class="number">12</span>,</span><br><span class="line">    		<span class="string">'num_leaves'</span>: <span class="number">16</span>,</span><br><span class="line">    		<span class="string">'learning_rate'</span>: <span class="number">0.07</span>,</span><br><span class="line">    		<span class="string">'verbosity'</span>:<span class="number">1</span>,</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	newdata[<span class="number">0</span>:r,<span class="number">0</span>:<span class="number">6812</span>] = data1[:,:]</span><br><span class="line">	newdata[<span class="number">0</span>:r,<span class="number">6812</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">0</span>,<span class="number">397</span>):</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> i &lt; x:</span><br><span class="line">			m = <span class="string">"%03d"</span> % i</span><br><span class="line">			path = <span class="string">'../train_data_split/train_feat_class_'</span> + m + <span class="string">'.mat'</span></span><br><span class="line">			data = sio.loadmat(path)</span><br><span class="line">			data = data[<span class="string">'train_feat_c'</span>]</span><br><span class="line"></span><br><span class="line">			[r1,c1] = data.shape</span><br><span class="line">			select_list = range(<span class="number">0</span>,r1 - <span class="number">1</span>)</span><br><span class="line">			index = random.sample(select_list,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> r &lt; <span class="number">200</span> :</span><br><span class="line">				newdata[r + i,<span class="number">0</span>:<span class="number">6812</span>] = data[index[<span class="number">0</span>],:]</span><br><span class="line">				newdata[r + i,<span class="number">6812</span>] = <span class="number">0</span></span><br><span class="line">			<span class="keyword">else</span>:</span><br><span class="line">				newdata[r + i*<span class="number">2</span>,<span class="number">0</span>:<span class="number">6812</span>] = data[index[<span class="number">0</span>],:]</span><br><span class="line">				newdata[r + i*<span class="number">2</span>+<span class="number">1</span>,<span class="number">0</span>:<span class="number">6812</span>] = data[index[<span class="number">1</span>],:]</span><br><span class="line"></span><br><span class="line">				newdata[r + i*<span class="number">2</span>:(i+<span class="number">1</span>)*<span class="number">2</span>,<span class="number">6812</span>] = <span class="number">0</span></span><br><span class="line">		<span class="keyword">if</span> i &gt; x:</span><br><span class="line">			m = <span class="string">"%03d"</span> % i</span><br><span class="line">			path = <span class="string">'../train_data_split/train_feat_class_'</span> + m + <span class="string">'.mat'</span></span><br><span class="line">			data = sio.loadmat(path)</span><br><span class="line">			data = data[<span class="string">'train_feat_c'</span>]</span><br><span class="line"></span><br><span class="line">			[r1,c1] = data.shape</span><br><span class="line">			select_list = range(<span class="number">0</span>,r1 - <span class="number">1</span>)</span><br><span class="line">			index = random.sample(select_list,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> r &lt; <span class="number">200</span> :</span><br><span class="line">				newdata[r + i<span class="number">-1</span>,<span class="number">0</span>:<span class="number">6812</span>] = data[index[<span class="number">0</span>],:]</span><br><span class="line">				newdata[r + i<span class="number">-1</span>,<span class="number">6812</span>] = <span class="number">0</span></span><br><span class="line">			<span class="keyword">else</span>:</span><br><span class="line">				newdata[r + (i <span class="number">-1</span>)*<span class="number">2</span>,<span class="number">0</span>:<span class="number">6812</span>] = data[index[<span class="number">0</span>],:]</span><br><span class="line">				newdata[r + (i <span class="number">-1</span>)*<span class="number">2</span>+<span class="number">1</span>,<span class="number">0</span>:<span class="number">6812</span>] = data[index[<span class="number">1</span>],:]</span><br><span class="line"></span><br><span class="line">				newdata[r + (i <span class="number">-1</span>)*<span class="number">2</span>:i*<span class="number">2</span>,<span class="number">6812</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">	print(x)</span><br><span class="line"></span><br><span class="line">	dtrain = lgb.Dataset(newdata[:,<span class="number">0</span>:<span class="number">6812</span>],newdata[:,<span class="number">6812</span>])</span><br><span class="line"></span><br><span class="line">	lgb.cv(lgb_params,dtrain)</span><br><span class="line"></span><br><span class="line">	model = lgb.train(lgb_params,dtrain)</span><br><span class="line"></span><br><span class="line">	pred = model.predict(test)</span><br><span class="line"></span><br><span class="line">	pred = np.mat(pred)</span><br><span class="line">	print(pred)</span><br><span class="line">	path2 = <span class="string">'../data_3_result/result_'</span> + n + <span class="string">'.txt'</span></span><br><span class="line">	np.savetxt(path2,pred)</span><br></pre></td></tr></table></figure><p></p><p>这是通过每个样本属于每个类别的概率中得到每个样本的属于类别的代码：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np      </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pred = np.zeros((<span class="number">19850</span>,<span class="number">397</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> xrange(<span class="number">0</span>,<span class="number">397</span>):</span><br><span class="line">	n = <span class="string">"%03d"</span> % x</span><br><span class="line">	path = <span class="string">'../data_3_result/result_'</span> + n + <span class="string">'.txt'</span></span><br><span class="line">	result = np.loadtxt(path)</span><br><span class="line">	pred[:,x] = result</span><br><span class="line"></span><br><span class="line">print(pred.shape)</span><br><span class="line">res = []</span><br><span class="line">idn = []</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> xrange(<span class="number">0</span>,<span class="number">19850</span>):</span><br><span class="line">	n = <span class="string">"%06d"</span> % (x + <span class="number">1</span>)</span><br><span class="line">	res.append(np.argmax(pred[x,:]))</span><br><span class="line">	idn.append(<span class="string">'img_'</span> + n)</span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line">rl =pd.DataFrame(&#123;<span class="string">'image'</span>:idn,<span class="string">'label'</span>:res&#125;)</span><br><span class="line"></span><br><span class="line">rl.to_csv(<span class="string">'../result/res2.csv'</span>,index=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p></p><p><strong>这样达到的得到的正确率为18.8%</strong></p><div class="post-announce">感谢您的阅读，本文由 <a href="http://yoursite.com">NABIJAN</a> 版权所有。如若转载，请注明出处：NABIJAN（<a href="http://yoursite.com/2018/09/15/Data-Mining-2018-Final-exam/">http://yoursite.com/2018/09/15/Data-Mining-2018-Final-exam/</a>）</div><div class="post__prevs"><div class="post__prev"></div><div class="post__prev post__prev--right"><a href="/2018/09/18/使用hexo-github搭建个人博客/" title="使用hexo+github搭建个人博客">使用hexo+github搭建个人博客<i class="iconfont icon-next"></i></a></div></div></div></article></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">日常学习与兴趣交流的个人博客</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/经验分享/">经验分享</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/数据结构/">数据结构</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/数据挖掘/">数据挖掘</a><span class="block-list-count">1</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2018/09/19/数据结构-图-graph/" title="数据结构---图(graph)"><div class="item__cover"><img src="/img/postgraduate.jpg" alt="数据结构---图(graph)"></div><div class="item__info"><h3 class="item__title">数据结构---图(graph)</h3><span class="item__text">2018-09-19</span></div></a></li><li class="latest-post-item"><a href="/2018/09/18/使用hexo-github搭建个人博客/" title="使用hexo+github搭建个人博客"><div class="item__cover"><img src="/img/share.jpg" alt="使用hexo+github搭建个人博客"></div><div class="item__info"><h3 class="item__title">使用hexo+github搭建个人博客</h3><span class="item__text">2018-09-18</span></div></a></li><li class="latest-post-item"><a href="/2018/09/15/Data-Mining-2018-Final-exam/" title="Data-Mining-2018-Final-exam"><div class="item__cover"><img src="/img/kaggle.jpeg" alt="Data-Mining-2018-Final-exam"></div><div class="item__info"><h3 class="item__title">Data-Mining-2018-Final-exam</h3><span class="item__text">2018-09-15</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/考研之路-图-graph/">-考研之路 -图(graph)</a></li><li class="tag-item"><a class="tag-link" href="/tags/Data-mining/">Data-mining</a></li><li class="tag-item"><a class="tag-link" href="/tags/github/">github</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站是基于 Hexo 搭建的静态资源博客，主要用于分享日常学习、生活的一些心得总结。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Guangzhou, Guangdong Province, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>abdnbjkeb@mail2.sysu.edu.cn</span></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="https://github.com/Mrminfive/hexo-theme-skapp" title="hexo-theme-skapp" target="_blank">hexo-theme-skapp</a></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">构建工具</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="https://hexo.io/" title="Blog Framework" target="_blank">Hexo</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>.</p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/NABIJAN" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="abdnbjkeb@mail2.sysu.edu.cn" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li><li class="social-network__item"><a href="/" target="_blank" title="weibo"><i class="iconfont icon-weibo"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script></body></html>